import AbstractChatProvider from "./AbstractChatProvider";
/**
 * LLM OpenAI Compatible Chat Provider
 * @template ChatMessage 消息类型
 * @template Input 请求参数类型
 * @template Output 响应数据类型
 */
export default class OpenAIChatProvider extends AbstractChatProvider {
  transformParams(requestParams, options) {
    return {
      ...(options?.params || {}),
      ...requestParams,
      messages: this.getMessages()
    };
  }
  transformLocalMessage(requestParams) {
    return requestParams?.messages || [];
  }
  transformMessage(info) {
    const {
      originMessage,
      chunk,
      responseHeaders
    } = info;
    let currentContent = '';
    let role = 'assistant';
    try {
      let message;
      if (responseHeaders.get('content-type')?.includes('text/event-stream')) {
        if (chunk && chunk.data?.trim() !== '[DONE]') {
          message = JSON.parse(chunk.data);
        }
      } else {
        message = chunk;
      }
      if (message) {
        message?.choices?.forEach(choice => {
          if (choice?.delta) {
            currentContent += choice.delta.content || '';
            role = choice.delta.role || 'assistant';
          } else if (choice?.message) {
            currentContent += choice.message.content || '';
            role = choice.message.role || 'assistant';
          }
        });
      }
    } catch (error) {
      console.error('transformMessage error', error);
    }
    const content = `${originMessage?.content || ''}${currentContent || ''}`;
    return {
      content,
      role
    };
  }
}